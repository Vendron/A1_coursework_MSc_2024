{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIg6enKVhhi4"
      },
      "source": [
        "\n",
        "\n",
        "## **COMP6685 Deep Learning Coursework A1**\n",
        "\n",
        "\n",
        "Individual (50% of total mark)\n",
        "\n",
        "\n",
        "**TASK:**\tYou are required to develop a phyton code with appropriate comments and answer questions.\n",
        "\n",
        "**Description**: Create a code using this temlate to train a Convolutional Neural Network (CNN) on the fashion MNIST dataset available at https://keras.io/api/datasets/fashion_mnist/ . \n",
        "\n",
        "Fashion MNIST is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images.\n",
        "\n",
        "The dataset should be imported in the code and one sample image should be visualised before applying the model.\n",
        "\n",
        "Define a CNN and comment the chosen parameters of the network. Apply a regularization method (L1, L2 or L1L2). Divide the dataset into training, validation and test set. Obtain the accuracy on the validation set and plot the final results using the data from the test set. Comment your lines of code appropriately to explain your solution.\n",
        "\n",
        "Enhance the model's performance to obtain the best or optimal validation accuracy. Further questions about final remarks on the results will be answered on the markdown defined in the template.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "Note: This is only a template. You can add more code/text cells if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FkERIusYhcK6"
      },
      "outputs": [],
      "source": [
        "## import data from at \n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [\n",
        "    {0, \"T-shirt/top\"}, \n",
        "    {1, \"Trouser\"}, \n",
        "    {2, \"Pullover\"},\n",
        "    {3,\"Dress\"},\n",
        "    {4, \"Coat\"},\n",
        "    {5, \"Sandal\"},\n",
        "    {6, \"Shirt\"},\n",
        "    {7, \"Sneaker\"},\n",
        "    {8, \"Bag\"},\n",
        "    {9, \"Ankle boot\"}\n",
        "]\n",
        "\n",
        "N_EPOCHS = 20  # Use 20 for better results\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 2\n",
        "OPTIMIZER = keras.optimizers.legacy.Adam()\n",
        "VALIDATION_SPLIT = 0.2\n",
        "FOLDS = 5\n",
        "IMG_ROWS, IMG_COLS = 28, 28  # Input dimensions of each MNIST image\n",
        "N_CLASSES = 10  # Number of outputs = number of digits\n",
        "INPUT_SHAPE = (28, 28, 1)  # Adjusted for Keras default\n",
        "\n",
        "\n",
        "# PDF paper https://bhu.ac.in/research_pub/jsr/Volumes/JSR_64_02_2020/51.pdf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qysRQbvOm1c4"
      },
      "source": [
        "Import the dataset and divide it appropriately into sets for cross-validation. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tV9PO1GBl5_6"
      },
      "outputs": [],
      "source": [
        "# Load and prepare the dataset\n",
        "(fashion_train_images, fashion_train_labels), (fashion_test_images, fashion_test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "fashion_train_images, fashion_test_images = fashion_train_images / 255.0, fashion_test_images / 255.0\n",
        "\n",
        "# Reshape images to fit the model input requirement\n",
        "fashion_train_images = fashion_train_images.reshape((fashion_train_images.shape[0], IMG_ROWS, IMG_COLS, 1))\n",
        "fashion_test_images = fashion_test_images.reshape((fashion_test_images.shape[0], IMG_ROWS, IMG_COLS, 1))\n",
        "\n",
        "# One-hot encode the labels\n",
        "fashion_train_labels = keras.utils.to_categorical(fashion_train_labels, N_CLASSES)\n",
        "fashion_test_labels = keras.utils.to_categorical(fashion_test_labels, N_CLASSES)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*your answer here*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2-xHphsvmG7F"
      },
      "source": [
        "Visualise a random sample image of the dataset. **(5 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bTTrIN_nnDWK"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize one random sample from the dataset\n",
        "plt.figure(figsize=(2,2))\n",
        "random_index = np.random.choice(fashion_train_images.shape[0])\n",
        "plt.imshow(fashion_train_images[random_index].reshape(28,28), cmap='gray')\n",
        "plt.title('Sample Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMhGFcimoUwz"
      },
      "source": [
        "Define your CNN model. Specify the network and training parameters and comment them. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "urupEGOFooUz"
      },
      "outputs": [],
      "source": [
        "def create_model(optimizer='adam', kernel_regularizer=keras.regularizers.l2(0.001)):\n",
        "    model = keras.Sequential([\n",
        "        # Convolutional layer with L2 regularization\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        \n",
        "        # Another convolutional layer\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        \n",
        "        # Flatten the output of the conv layers to feed into the dense layer\n",
        "        layers.Flatten(),\n",
        "        \n",
        "        # Dense layer with L2 regularization\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "        \n",
        "        # Output layer with softmax for multi-class classification\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# your code here\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "csCYqn-9pDuJ"
      },
      "source": [
        "Train the CNN model using k-fold cross-validation. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xESPeCWnpJek"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 - 11s - loss: 0.6457 - accuracy: 0.8183 - val_loss: 0.5291 - val_accuracy: 0.8516 - 11s/epoch - 7ms/step\n",
            "Epoch 2/10\n",
            "1500/1500 - 11s - loss: 0.4777 - accuracy: 0.8648 - val_loss: 0.4546 - val_accuracy: 0.8740 - 11s/epoch - 7ms/step\n",
            "Epoch 3/10\n",
            "1500/1500 - 11s - loss: 0.4424 - accuracy: 0.8767 - val_loss: 0.4514 - val_accuracy: 0.8699 - 11s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "1500/1500 - 11s - loss: 0.4166 - accuracy: 0.8853 - val_loss: 0.4211 - val_accuracy: 0.8827 - 11s/epoch - 7ms/step\n",
            "Epoch 5/10\n",
            "1500/1500 - 10s - loss: 0.4029 - accuracy: 0.8887 - val_loss: 0.4097 - val_accuracy: 0.8864 - 10s/epoch - 7ms/step\n",
            "Epoch 6/10\n",
            "1500/1500 - 10s - loss: 0.3897 - accuracy: 0.8929 - val_loss: 0.3933 - val_accuracy: 0.8923 - 10s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "1500/1500 - 10s - loss: 0.3790 - accuracy: 0.8959 - val_loss: 0.3937 - val_accuracy: 0.8906 - 10s/epoch - 7ms/step\n",
            "Epoch 8/10\n",
            "1500/1500 - 11s - loss: 0.3712 - accuracy: 0.8986 - val_loss: 0.3829 - val_accuracy: 0.8910 - 11s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "1500/1500 - 11s - loss: 0.3638 - accuracy: 0.9008 - val_loss: 0.3973 - val_accuracy: 0.8899 - 11s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "1500/1500 - 11s - loss: 0.3595 - accuracy: 0.9022 - val_loss: 0.3665 - val_accuracy: 0.8992 - 11s/epoch - 7ms/step\n",
            "Score for fold 1: loss of 0.3664822280406952; accuracy of 89.92499709129333%\n",
            "Epoch 1/10\n",
            "1500/1500 - 11s - loss: 0.6440 - accuracy: 0.8205 - val_loss: 0.5103 - val_accuracy: 0.8590 - 11s/epoch - 7ms/step\n",
            "Epoch 2/10\n",
            "1500/1500 - 10s - loss: 0.4770 - accuracy: 0.8650 - val_loss: 0.4411 - val_accuracy: 0.8777 - 10s/epoch - 7ms/step\n",
            "Epoch 3/10\n",
            "1500/1500 - 10s - loss: 0.4425 - accuracy: 0.8751 - val_loss: 0.4505 - val_accuracy: 0.8721 - 10s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "1500/1500 - 10s - loss: 0.4202 - accuracy: 0.8823 - val_loss: 0.4164 - val_accuracy: 0.8864 - 10s/epoch - 7ms/step\n",
            "Epoch 5/10\n",
            "1500/1500 - 11s - loss: 0.4019 - accuracy: 0.8889 - val_loss: 0.4011 - val_accuracy: 0.8905 - 11s/epoch - 7ms/step\n",
            "Epoch 6/10\n",
            "1500/1500 - 10s - loss: 0.3908 - accuracy: 0.8906 - val_loss: 0.3964 - val_accuracy: 0.8890 - 10s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "1500/1500 - 11s - loss: 0.3817 - accuracy: 0.8955 - val_loss: 0.3998 - val_accuracy: 0.8878 - 11s/epoch - 7ms/step\n",
            "Epoch 8/10\n",
            "1500/1500 - 11s - loss: 0.3708 - accuracy: 0.8976 - val_loss: 0.4370 - val_accuracy: 0.8742 - 11s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "1500/1500 - 11s - loss: 0.3688 - accuracy: 0.8987 - val_loss: 0.3609 - val_accuracy: 0.9033 - 11s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "1500/1500 - 11s - loss: 0.3587 - accuracy: 0.9021 - val_loss: 0.3624 - val_accuracy: 0.9003 - 11s/epoch - 7ms/step\n",
            "Score for fold 2: loss of 0.3624473512172699; accuracy of 90.03333449363708%\n",
            "Epoch 1/10\n",
            "1500/1500 - 11s - loss: 0.6362 - accuracy: 0.8183 - val_loss: 0.4952 - val_accuracy: 0.8662 - 11s/epoch - 8ms/step\n",
            "Epoch 2/10\n",
            "1500/1500 - 11s - loss: 0.4719 - accuracy: 0.8665 - val_loss: 0.4983 - val_accuracy: 0.8511 - 11s/epoch - 8ms/step\n",
            "Epoch 3/10\n",
            "1500/1500 - 11s - loss: 0.4393 - accuracy: 0.8761 - val_loss: 0.4094 - val_accuracy: 0.8840 - 11s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "1500/1500 - 11s - loss: 0.4148 - accuracy: 0.8821 - val_loss: 0.3974 - val_accuracy: 0.8886 - 11s/epoch - 7ms/step\n",
            "Epoch 5/10\n",
            "1500/1500 - 11s - loss: 0.4008 - accuracy: 0.8878 - val_loss: 0.3945 - val_accuracy: 0.8868 - 11s/epoch - 7ms/step\n",
            "Epoch 6/10\n",
            "1500/1500 - 11s - loss: 0.3877 - accuracy: 0.8910 - val_loss: 0.3945 - val_accuracy: 0.8863 - 11s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "1500/1500 - 11s - loss: 0.3807 - accuracy: 0.8945 - val_loss: 0.3788 - val_accuracy: 0.8967 - 11s/epoch - 7ms/step\n",
            "Epoch 8/10\n",
            "1500/1500 - 11s - loss: 0.3710 - accuracy: 0.8979 - val_loss: 0.3699 - val_accuracy: 0.8958 - 11s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "1500/1500 - 11s - loss: 0.3634 - accuracy: 0.9002 - val_loss: 0.3685 - val_accuracy: 0.8967 - 11s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "1500/1500 - 11s - loss: 0.3606 - accuracy: 0.8999 - val_loss: 0.3598 - val_accuracy: 0.9010 - 11s/epoch - 7ms/step\n",
            "Score for fold 3: loss of 0.35979124903678894; accuracy of 90.10000228881836%\n",
            "Epoch 1/10\n",
            "1500/1500 - 11s - loss: 0.6425 - accuracy: 0.8215 - val_loss: 0.4989 - val_accuracy: 0.8603 - 11s/epoch - 7ms/step\n",
            "Epoch 2/10\n",
            "1500/1500 - 11s - loss: 0.4762 - accuracy: 0.8672 - val_loss: 0.4760 - val_accuracy: 0.8627 - 11s/epoch - 7ms/step\n",
            "Epoch 3/10\n",
            "1500/1500 - 11s - loss: 0.4401 - accuracy: 0.8752 - val_loss: 0.4553 - val_accuracy: 0.8737 - 11s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "1500/1500 - 11s - loss: 0.4146 - accuracy: 0.8845 - val_loss: 0.4156 - val_accuracy: 0.8837 - 11s/epoch - 8ms/step\n",
            "Epoch 5/10\n",
            "1500/1500 - 11s - loss: 0.4030 - accuracy: 0.8870 - val_loss: 0.4078 - val_accuracy: 0.8860 - 11s/epoch - 7ms/step\n",
            "Epoch 6/10\n",
            "1500/1500 - 11s - loss: 0.3891 - accuracy: 0.8921 - val_loss: 0.3905 - val_accuracy: 0.8913 - 11s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "1500/1500 - 11s - loss: 0.3793 - accuracy: 0.8952 - val_loss: 0.4043 - val_accuracy: 0.8884 - 11s/epoch - 7ms/step\n",
            "Epoch 8/10\n",
            "1500/1500 - 11s - loss: 0.3693 - accuracy: 0.8982 - val_loss: 0.3915 - val_accuracy: 0.8919 - 11s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "1500/1500 - 11s - loss: 0.3649 - accuracy: 0.8995 - val_loss: 0.3761 - val_accuracy: 0.8976 - 11s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "1500/1500 - 11s - loss: 0.3587 - accuracy: 0.9010 - val_loss: 0.3687 - val_accuracy: 0.9020 - 11s/epoch - 7ms/step\n",
            "Score for fold 4: loss of 0.3687325716018677; accuracy of 90.20000100135803%\n",
            "Epoch 1/10\n",
            "1500/1500 - 11s - loss: 0.6420 - accuracy: 0.8184 - val_loss: 0.4951 - val_accuracy: 0.8618 - 11s/epoch - 7ms/step\n",
            "Epoch 2/10\n",
            "1500/1500 - 11s - loss: 0.4781 - accuracy: 0.8653 - val_loss: 0.4312 - val_accuracy: 0.8827 - 11s/epoch - 7ms/step\n",
            "Epoch 3/10\n",
            "1500/1500 - 11s - loss: 0.4390 - accuracy: 0.8770 - val_loss: 0.4880 - val_accuracy: 0.8554 - 11s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "1500/1500 - 11s - loss: 0.4182 - accuracy: 0.8844 - val_loss: 0.4132 - val_accuracy: 0.8823 - 11s/epoch - 7ms/step\n",
            "Epoch 5/10\n",
            "1500/1500 - 11s - loss: 0.4022 - accuracy: 0.8875 - val_loss: 0.4073 - val_accuracy: 0.8845 - 11s/epoch - 8ms/step\n",
            "Epoch 6/10\n",
            "1500/1500 - 11s - loss: 0.3897 - accuracy: 0.8930 - val_loss: 0.3961 - val_accuracy: 0.8902 - 11s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "1500/1500 - 11s - loss: 0.3793 - accuracy: 0.8962 - val_loss: 0.3738 - val_accuracy: 0.8976 - 11s/epoch - 7ms/step\n",
            "Epoch 8/10\n",
            "1500/1500 - 10s - loss: 0.3712 - accuracy: 0.8976 - val_loss: 0.3826 - val_accuracy: 0.8911 - 10s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "1500/1500 - 10s - loss: 0.3643 - accuracy: 0.8994 - val_loss: 0.3643 - val_accuracy: 0.8991 - 10s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "1500/1500 - 10s - loss: 0.3570 - accuracy: 0.9020 - val_loss: 0.3750 - val_accuracy: 0.8968 - 10s/epoch - 7ms/step\n",
            "Score for fold 5: loss of 0.37502697110176086; accuracy of 89.68333601951599%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "# Prepare k-fold cross-validation\n",
        "FOLDS = 5\n",
        "EPOCHS = 10\n",
        "VERBOSE = 2\n",
        "OPTIMIZER = keras.optimizers.legacy.Adam()\n",
        "\n",
        "kfold = KFold(n_splits=FOLDS, shuffle=True)\n",
        "\n",
        "fold_num = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(fashion_train_images, fashion_train_labels):\n",
        "    # Create model\n",
        "    model = create_model()\n",
        "    \n",
        "    # Fit model\n",
        "    history = model.fit(fashion_train_images[train], fashion_train_labels[train], \n",
        "                        EPOCHS, \n",
        "                        validation_data=(fashion_train_images[test], fashion_train_labels[test]), \n",
        "                        verbose=2)\n",
        "    \n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(fashion_train_images[test], fashion_train_labels[test], verbose=0)\n",
        "    print(f'Score for fold {fold_num}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "    \n",
        "    fold_num += 1\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FFMiFtDCpjMG"
      },
      "source": [
        "Evaluate your model in cross-validation. Calculate and print the loss and accuracy scores in each fold. Print the average cross-validation accuracy and loss your network achieved (in all folds). **(15 marks)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WnCeV6qP6xmT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "Score per fold\n",
            "----------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.3664822280406952 - Accuracy: 89.92499709129333%\n",
            "----------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.3624473512172699 - Accuracy: 90.03333449363708%\n",
            "----------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.35979124903678894 - Accuracy: 90.10000228881836%\n",
            "----------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.3687325716018677 - Accuracy: 90.20000100135803%\n",
            "----------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.37502697110176086 - Accuracy: 89.68333601951599%\n",
            "----------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 89.98833417892456 (+- 0.17682369904669634)\n",
            "> Loss: 0.3664960741996765\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "# Print the average scores\n",
        "print('----------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "    print('----------------------------------------------------------------')\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('----------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('----------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GvX1moIqqm0"
      },
      "source": [
        "*your answer here*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S48e3kq_qCCi"
      },
      "source": [
        "Plot the final results (accuracy/loss) on the test set in each fold. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DLLIrvy2psKZ"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'acc_per_fold' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plotting accuracy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_folds\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[43macc_per_fold\u001b[49m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel accuracy on Test Set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold Number\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'acc_per_fold' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# your code here\n",
        "num_folds = FOLDS\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plotting accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_folds+1), acc_per_fold, marker='o', linestyle='-', color='blue')\n",
        "plt.title('Model accuracy on Test Set')\n",
        "plt.xlabel('Fold Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(range(1, num_folds+1))\n",
        "plt.grid(True)\n",
        "\n",
        "# Plotting loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_folds+1), loss_per_fold, marker='o', linestyle='-', color='red')\n",
        "plt.title('Model loss on Test Set')\n",
        "plt.xlabel('Fold Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(range(1, num_folds+1))\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImI7busBrCie"
      },
      "source": [
        "Additional questions:\n",
        "\n",
        "\n",
        "*   Describe whether you found any differences in the network’s accuracy when applying regularisation compared to not applying it. If there were differences, which regularisation did you use? If no differences were found, what could be the reason? **(10 marks)**\n",
        "\n",
        "*your answer here*\n",
        "\n",
        "*   Write your conclusions about the results achieved with your model on the fashion MNIST dataset and ideas to improve these results/performance further. **(10 marks)**\n",
        "\n",
        "*your answer here*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcSc_1JiqRA3"
      },
      "source": [
        "Additional remarks:\n",
        "\n",
        "*   Code outline appropriately commented. **(10 marks)**\n",
        "*   Code running without errors. **(10 marks)**\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3e7af04d29b7c7f09156ce72bf463dad5c8b45a218773abf1ffb50277174388"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
